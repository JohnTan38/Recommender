{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3a1dd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from pprint import pprint\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Reshape, Dot\n",
    "from keras.layers.embeddings import Embedding\n",
    "#from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Concatenate, Dense, Dropout\n",
    "from keras.layers import Add, Activation, Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68c11335",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'https://raw.githubusercontent.com/JohnTan38/Recommender/main/dat/'\n",
    "mnames = ['movie_id','title','genres']\n",
    "movies = pd.read_table(path+\"movies.dat.txt\", sep='::', header=None,names=mnames,engine='python', encoding='latin-1')\n",
    "\n",
    "rnames = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "ratings = pd.read_table(path+\"ratings.dat\", sep='::', header=None, names=rnames,engine='python')\n",
    "\n",
    "unames = ['user_id','gender','age','occ','zipcode']\n",
    "users = pd.read_table(path+\"users.dat.txt\",sep='::', header=None, names=unames,engine='python')\n",
    "\n",
    "#path_dir = (r'https://raw.githubusercontent.com/JohnTan38/Recommender/main/dat/')\n",
    "#users = pd.read_csv(path_dir + 'users.csv', sep='\\t', encoding='latin-1', usecols=['user_id', 'gender', 'zipcode', 'age_desc', 'occ_desc'])\n",
    "#https://github.com/rposhala/Recommender-System-on-MovieLens-dataset/blob/main/Recommender_System_using_Softmax_DNN.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c29bf984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Airplane! (1980)</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Aladdin (1992)</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Antz (1998)</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Apollo 13 (1995)</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Awakenings (1990)</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id              title  rating\n",
       "0        1   Airplane! (1980)     4.0\n",
       "1        1     Aladdin (1992)     4.0\n",
       "2        1        Antz (1998)     4.0\n",
       "3        1   Apollo 13 (1995)     5.0\n",
       "4        1  Awakenings (1990)     5.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_dataset = pd.merge(ratings, movies, how='inner', on='movie_id')\n",
    "#merged_dataset.head()\n",
    "\n",
    "refined_dataset = merged_dataset.groupby(by=['user_id','title'], as_index=False).agg({\"rating\":\"mean\"})\n",
    "refined_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "267874ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6040, 3706, 1.0, 5.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_enc = LabelEncoder()\n",
    "refined_dataset['user'] = user_enc.fit_transform(refined_dataset['user_id'].values)\n",
    "n_users = refined_dataset['user'].nunique()\n",
    "\n",
    "item_enc = LabelEncoder()\n",
    "refined_dataset['movie'] = item_enc.fit_transform(refined_dataset['title'].values)\n",
    "n_movies = refined_dataset['movie'].nunique()\n",
    "\n",
    "refined_dataset['rating'] = refined_dataset['rating'].values.astype(np.float32)\n",
    "min_rating = min(refined_dataset['rating'])\n",
    "max_rating = max(refined_dataset['rating'])\n",
    "n_users, n_movies, min_rating, max_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ad482ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((900188, 2), (100021, 2), (900188,), (100021,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = refined_dataset[['user', 'movie']].values\n",
    "y = refined_dataset['rating'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=50)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ea72d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_factors = 150 #Defining number of factors to be considered by embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc9f23fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[4343, 1154],\n",
       "        [5184, 1007],\n",
       "        [1604, 3342],\n",
       "        ...,\n",
       "        [1448,   12],\n",
       "        [ 689, 3293],\n",
       "        [5625, 2743]], dtype=int64),\n",
       " [array([4343, 5184, 1604, ..., 1448,  689, 5625], dtype=int64),\n",
       "  array([1154, 1007, 3342, ...,   12, 3293, 2743], dtype=int64)],\n",
       " (900188,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_array = [X_train[:, 0], X_train[:, 1]]\n",
    "X_test_array = [X_test[:, 0], X_test[:, 1]]\n",
    "\n",
    "X_train, X_train_array, X_train_array[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0993b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = (y_train - min_rating)/(max_rating - min_rating)\n",
    "y_test = (y_test - min_rating)/(max_rating - min_rating) #Normalizing the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5432ce94",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initializing a input layer for users\n",
    "user = tf.keras.layers.Input(shape = (1,))\n",
    "\n",
    "## Embedding layer for n_factors of users\n",
    "u = keras.layers.embeddings.Embedding(n_users, n_factors, embeddings_initializer = 'he_normal', embeddings_regularizer = tf.keras.regularizers.l2(1e-6))(user)\n",
    "u = tf.keras.layers.Reshape((n_factors,))(u)\n",
    "\n",
    "## Initializing a input layer for movies\n",
    "movie = tf.keras.layers.Input(shape = (1,))\n",
    "\n",
    "## Embedding layer for n_factors of movies\n",
    "m = keras.layers.embeddings.Embedding(n_movies, n_factors, embeddings_initializer = 'he_normal', embeddings_regularizer=tf.keras.regularizers.l2(1e-6))(movie)\n",
    "m = tf.keras.layers.Reshape((n_factors,))(m)\n",
    "\n",
    "## stacking up both user and movie embeddings\n",
    "x = tf.keras.layers.Concatenate()([u,m])\n",
    "x = tf.keras.layers.Dropout(0.05)(x)\n",
    "\n",
    "## Adding a Dense layer to the architecture\n",
    "x = tf.keras.layers.Dense(32, kernel_initializer='he_normal')(x)\n",
    "x = tf.keras.layers.Activation(activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.05)(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(16, kernel_initializer='he_normal')(x)\n",
    "x = tf.keras.layers.Activation(activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.05)(x)\n",
    "\n",
    "## Adding an Output layer with Sigmoid activation funtion which gives output between 0 and 1\n",
    "x = tf.keras.layers.Dense(9)(x)\n",
    "x = tf.keras.layers.Activation(activation='softmax')(x)\n",
    "\n",
    "## Adding a Lambda layer to convert the output to rating by scaling it with the help of available rating information\n",
    "# x = tf.keras.layers.Lambda(lambda x: x*(max_rating - min_rating) + min_rating)(x)\n",
    "\n",
    "## Defining the model\n",
    "model = tf.keras.models.Model(inputs=[user,movie], outputs=x)\n",
    "# optimizer = tf.keras.optimizers.Adam(lr=0.001)\n",
    "# optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.005,\n",
    "    # rho=0.9, momentum=0.01, epsilon=1e-07)\n",
    "\n",
    "## Compiling the model\n",
    "# model.compile(loss='binary_crossentropy', optimizer = optimizer)\n",
    "# model.compile(loss='mean_squared_error', optimizer = optimizer,metrics=['accuracy'])\n",
    "model.compile(optimizer='sgd', loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b35005",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01e0a653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "7033/7033 [==============================] - 77s 11ms/step - loss: 0.5646 - accuracy: 0.0562 - val_loss: 0.5351 - val_accuracy: 0.0559 - lr: 0.0100\n",
      "Epoch 2/70\n",
      "7033/7033 [==============================] - 78s 11ms/step - loss: 0.5300 - accuracy: 0.0562 - val_loss: 0.5172 - val_accuracy: 0.0559 - lr: 0.0100\n",
      "Epoch 3/70\n",
      "7033/7033 [==============================] - 80s 11ms/step - loss: 0.4965 - accuracy: 0.0742 - val_loss: 0.4725 - val_accuracy: 0.1000 - lr: 0.0100\n",
      "Epoch 4/70\n",
      "7033/7033 [==============================] - 80s 11ms/step - loss: 0.4632 - accuracy: 0.1009 - val_loss: 0.4464 - val_accuracy: 0.1060 - lr: 0.0100\n",
      "Epoch 5/70\n",
      "7033/7033 [==============================] - 80s 11ms/step - loss: 0.4447 - accuracy: 0.1149 - val_loss: 0.4354 - val_accuracy: 0.1263 - lr: 0.0100\n",
      "Epoch 6/70\n",
      "7033/7033 [==============================] - 83s 12ms/step - loss: 0.4359 - accuracy: 0.1218 - val_loss: 0.4321 - val_accuracy: 0.1126 - lr: 0.0100\n",
      "Epoch 7/70\n",
      "7033/7033 [==============================] - 81s 11ms/step - loss: 0.4308 - accuracy: 0.1250 - val_loss: 0.4287 - val_accuracy: 0.1232 - lr: 0.0100\n",
      "Epoch 8/70\n",
      "7033/7033 [==============================] - 84s 12ms/step - loss: 0.4280 - accuracy: 0.1266 - val_loss: 0.4269 - val_accuracy: 0.1316 - lr: 0.0100\n",
      "Epoch 9/70\n",
      "7033/7033 [==============================] - 86s 12ms/step - loss: 0.4253 - accuracy: 0.1280 - val_loss: 0.4267 - val_accuracy: 0.1205 - lr: 0.0100\n",
      "Epoch 10/70\n",
      "7033/7033 [==============================] - 83s 12ms/step - loss: 0.4236 - accuracy: 0.1285 - val_loss: 0.4252 - val_accuracy: 0.1365 - lr: 0.0100\n",
      "Epoch 11/70\n",
      "7033/7033 [==============================] - 83s 12ms/step - loss: 0.4217 - accuracy: 0.1289 - val_loss: 0.4242 - val_accuracy: 0.1310 - lr: 0.0100\n",
      "Epoch 12/70\n",
      "7033/7033 [==============================] - 84s 12ms/step - loss: 0.4204 - accuracy: 0.1296 - val_loss: 0.4239 - val_accuracy: 0.1313 - lr: 0.0100\n",
      "Epoch 13/70\n",
      "7033/7033 [==============================] - 82s 12ms/step - loss: 0.4189 - accuracy: 0.1299 - val_loss: 0.4243 - val_accuracy: 0.1128 - lr: 0.0100\n",
      "Epoch 14/70\n",
      "7033/7033 [==============================] - 81s 11ms/step - loss: 0.4179 - accuracy: 0.1296 - val_loss: 0.4230 - val_accuracy: 0.1385 - lr: 0.0100\n",
      "Epoch 15/70\n",
      "7033/7033 [==============================] - 79s 11ms/step - loss: 0.4167 - accuracy: 0.1300 - val_loss: 0.4226 - val_accuracy: 0.1333 - lr: 0.0100\n",
      "Epoch 16/70\n",
      "7033/7033 [==============================] - 79s 11ms/step - loss: 0.4155 - accuracy: 0.1299 - val_loss: 0.4227 - val_accuracy: 0.1280 - lr: 0.0100\n",
      "Epoch 17/70\n",
      "7033/7033 [==============================] - 81s 12ms/step - loss: 0.4146 - accuracy: 0.1302 - val_loss: 0.4216 - val_accuracy: 0.1251 - lr: 0.0100\n",
      "Epoch 18/70\n",
      "7033/7033 [==============================] - 90s 13ms/step - loss: 0.4136 - accuracy: 0.1306 - val_loss: 0.4221 - val_accuracy: 0.1346 - lr: 0.0100\n",
      "Epoch 19/70\n",
      "7033/7033 [==============================] - 90s 13ms/step - loss: 0.4131 - accuracy: 0.1303 - val_loss: 0.4215 - val_accuracy: 0.1243 - lr: 0.0100\n",
      "Epoch 20/70\n",
      "7033/7033 [==============================] - 92s 13ms/step - loss: 0.4122 - accuracy: 0.1308 - val_loss: 0.4212 - val_accuracy: 0.1364 - lr: 0.0100\n",
      "Epoch 21/70\n",
      "7033/7033 [==============================] - 82s 12ms/step - loss: 0.4116 - accuracy: 0.1307 - val_loss: 0.4217 - val_accuracy: 0.1231 - lr: 0.0100\n",
      "Epoch 22/70\n",
      "7033/7033 [==============================] - 81s 12ms/step - loss: 0.4109 - accuracy: 0.1311 - val_loss: 0.4218 - val_accuracy: 0.1289 - lr: 0.0100\n",
      "Epoch 23/70\n",
      "7029/7033 [============================>.] - ETA: 0s - loss: 0.4102 - accuracy: 0.1316\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.007499999832361937.\n",
      "7033/7033 [==============================] - 81s 12ms/step - loss: 0.4102 - accuracy: 0.1316 - val_loss: 0.4214 - val_accuracy: 0.1328 - lr: 0.0100\n",
      "Epoch 24/70\n",
      "7033/7033 [==============================] - 83s 12ms/step - loss: 0.4089 - accuracy: 0.1324 - val_loss: 0.4209 - val_accuracy: 0.1356 - lr: 0.0075\n",
      "Epoch 25/70\n",
      "7033/7033 [==============================] - 80s 11ms/step - loss: 0.4085 - accuracy: 0.1326 - val_loss: 0.4210 - val_accuracy: 0.1267 - lr: 0.0075\n",
      "Epoch 26/70\n",
      "7033/7033 [==============================] - 84s 12ms/step - loss: 0.4080 - accuracy: 0.1325 - val_loss: 0.4213 - val_accuracy: 0.1261 - lr: 0.0075\n",
      "Epoch 27/70\n",
      "7032/7033 [============================>.] - ETA: 0s - loss: 0.4076 - accuracy: 0.1328\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.005624999874271452.\n",
      "7033/7033 [==============================] - 80s 11ms/step - loss: 0.4076 - accuracy: 0.1328 - val_loss: 0.4210 - val_accuracy: 0.1265 - lr: 0.0075\n",
      "Epoch 28/70\n",
      "7033/7033 [==============================] - 77s 11ms/step - loss: 0.4065 - accuracy: 0.1336 - val_loss: 0.4213 - val_accuracy: 0.1321 - lr: 0.0056\n",
      "Epoch 29/70\n",
      "7033/7033 [==============================] - 77s 11ms/step - loss: 0.4062 - accuracy: 0.1336 - val_loss: 0.4215 - val_accuracy: 0.1298 - lr: 0.0056\n",
      "Epoch 30/70\n",
      "7029/7033 [============================>.] - ETA: 0s - loss: 0.4059 - accuracy: 0.1337\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.004218749818392098.\n",
      "7033/7033 [==============================] - 77s 11ms/step - loss: 0.4059 - accuracy: 0.1338 - val_loss: 0.4213 - val_accuracy: 0.1355 - lr: 0.0056\n",
      "Epoch 31/70\n",
      "7033/7033 [==============================] - 79s 11ms/step - loss: 0.4051 - accuracy: 0.1344 - val_loss: 0.4215 - val_accuracy: 0.1281 - lr: 0.0042\n",
      "Epoch 32/70\n",
      "7033/7033 [==============================] - 84s 12ms/step - loss: 0.4048 - accuracy: 0.1342 - val_loss: 0.4212 - val_accuracy: 0.1310 - lr: 0.0042\n",
      "Epoch 33/70\n",
      "7032/7033 [============================>.] - ETA: 0s - loss: 0.4044 - accuracy: 0.1343\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.003164062276482582.\n",
      "7033/7033 [==============================] - 83s 12ms/step - loss: 0.4044 - accuracy: 0.1343 - val_loss: 0.4210 - val_accuracy: 0.1300 - lr: 0.0042\n",
      "Epoch 34/70\n",
      "7033/7033 [==============================] - 78s 11ms/step - loss: 0.4039 - accuracy: 0.1349 - val_loss: 0.4211 - val_accuracy: 0.1276 - lr: 0.0032\n",
      "Epoch 35/70\n",
      "7033/7033 [==============================] - 77s 11ms/step - loss: 0.4036 - accuracy: 0.1347 - val_loss: 0.4216 - val_accuracy: 0.1264 - lr: 0.0032\n",
      "Epoch 36/70\n",
      "7033/7033 [==============================] - ETA: 0s - loss: 0.4033 - accuracy: 0.1351\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0023730467073619366.\n",
      "7033/7033 [==============================] - 80s 11ms/step - loss: 0.4033 - accuracy: 0.1351 - val_loss: 0.4209 - val_accuracy: 0.1321 - lr: 0.0032\n",
      "Epoch 37/70\n",
      "7033/7033 [==============================] - 79s 11ms/step - loss: 0.4029 - accuracy: 0.1350 - val_loss: 0.4208 - val_accuracy: 0.1327 - lr: 0.0024\n",
      "Epoch 38/70\n",
      "7033/7033 [==============================] - 80s 11ms/step - loss: 0.4026 - accuracy: 0.1354 - val_loss: 0.4211 - val_accuracy: 0.1305 - lr: 0.0024\n",
      "Epoch 39/70\n",
      "7031/7033 [============================>.] - ETA: 0s - loss: 0.4026 - accuracy: 0.1353\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0017797850305214524.\n",
      "7033/7033 [==============================] - 77s 11ms/step - loss: 0.4026 - accuracy: 0.1353 - val_loss: 0.4212 - val_accuracy: 0.1300 - lr: 0.0024\n",
      "Epoch 40/70\n",
      "7033/7033 [==============================] - 79s 11ms/step - loss: 0.4021 - accuracy: 0.1357 - val_loss: 0.4214 - val_accuracy: 0.1284 - lr: 0.0018\n",
      "Epoch 41/70\n",
      "7033/7033 [==============================] - 78s 11ms/step - loss: 0.4020 - accuracy: 0.1358 - val_loss: 0.4212 - val_accuracy: 0.1298 - lr: 0.0018\n",
      "Epoch 42/70\n",
      "7033/7033 [==============================] - 80s 11ms/step - loss: 0.4020 - accuracy: 0.1359 - val_loss: 0.4206 - val_accuracy: 0.1297 - lr: 0.0018\n",
      "Epoch 43/70\n",
      "7033/7033 [==============================] - 79s 11ms/step - loss: 0.4019 - accuracy: 0.1358 - val_loss: 0.4208 - val_accuracy: 0.1311 - lr: 0.0018\n",
      "Epoch 44/70\n",
      "7033/7033 [==============================] - 78s 11ms/step - loss: 0.4017 - accuracy: 0.1361 - val_loss: 0.4211 - val_accuracy: 0.1274 - lr: 0.0018\n",
      "Epoch 45/70\n",
      "7030/7033 [============================>.] - ETA: 0s - loss: 0.4018 - accuracy: 0.1359\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0013348387728910893.\n",
      "7033/7033 [==============================] - 78s 11ms/step - loss: 0.4018 - accuracy: 0.1359 - val_loss: 0.4213 - val_accuracy: 0.1297 - lr: 0.0018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/70\n",
      "7033/7033 [==============================] - 79s 11ms/step - loss: 0.4013 - accuracy: 0.1363 - val_loss: 0.4208 - val_accuracy: 0.1325 - lr: 0.0013\n",
      "Epoch 47/70\n",
      "7033/7033 [==============================] - 81s 12ms/step - loss: 0.4012 - accuracy: 0.1362 - val_loss: 0.4207 - val_accuracy: 0.1296 - lr: 0.0013\n",
      "Epoch 48/70\n",
      "7029/7033 [============================>.] - ETA: 0s - loss: 0.4010 - accuracy: 0.1362\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0010011291014961898.\n",
      "7033/7033 [==============================] - 79s 11ms/step - loss: 0.4010 - accuracy: 0.1362 - val_loss: 0.4211 - val_accuracy: 0.1310 - lr: 0.0013\n",
      "Epoch 49/70\n",
      "7033/7033 [==============================] - 79s 11ms/step - loss: 0.4009 - accuracy: 0.1363 - val_loss: 0.4210 - val_accuracy: 0.1313 - lr: 0.0010\n",
      "Epoch 50/70\n",
      "7033/7033 [==============================] - 80s 11ms/step - loss: 0.4009 - accuracy: 0.1365 - val_loss: 0.4207 - val_accuracy: 0.1336 - lr: 0.0010\n",
      "Epoch 51/70\n",
      "7030/7033 [============================>.] - ETA: 0s - loss: 0.4008 - accuracy: 0.1365\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0007508468697778881.\n",
      "7033/7033 [==============================] - 77s 11ms/step - loss: 0.4008 - accuracy: 0.1365 - val_loss: 0.4208 - val_accuracy: 0.1332 - lr: 0.0010\n",
      "Epoch 52/70\n",
      "7033/7033 [==============================] - 80s 11ms/step - loss: 0.4005 - accuracy: 0.1364 - val_loss: 0.4209 - val_accuracy: 0.1332 - lr: 7.5085e-04\n",
      "Epoch 53/70\n",
      "7033/7033 [==============================] - 77s 11ms/step - loss: 0.4005 - accuracy: 0.1367 - val_loss: 0.4210 - val_accuracy: 0.1320 - lr: 7.5085e-04\n",
      "Epoch 54/70\n",
      "7029/7033 [============================>.] - ETA: 0s - loss: 0.4003 - accuracy: 0.1367\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.000563135152333416.\n",
      "7033/7033 [==============================] - 79s 11ms/step - loss: 0.4003 - accuracy: 0.1367 - val_loss: 0.4211 - val_accuracy: 0.1313 - lr: 7.5085e-04\n",
      "Epoch 55/70\n",
      "7033/7033 [==============================] - 77s 11ms/step - loss: 0.4004 - accuracy: 0.1365 - val_loss: 0.4211 - val_accuracy: 0.1314 - lr: 5.6314e-04\n",
      "Epoch 56/70\n",
      "7033/7033 [==============================] - 78s 11ms/step - loss: 0.4003 - accuracy: 0.1365 - val_loss: 0.4209 - val_accuracy: 0.1349 - lr: 5.6314e-04\n",
      "Epoch 57/70\n",
      "7032/7033 [============================>.] - ETA: 0s - loss: 0.4002 - accuracy: 0.1371\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.0004223513533361256.\n",
      "7033/7033 [==============================] - 80s 11ms/step - loss: 0.4002 - accuracy: 0.1371 - val_loss: 0.4210 - val_accuracy: 0.1301 - lr: 5.6314e-04\n",
      "Epoch 58/70\n",
      "7033/7033 [==============================] - 77s 11ms/step - loss: 0.4000 - accuracy: 0.1366 - val_loss: 0.4211 - val_accuracy: 0.1341 - lr: 4.2235e-04\n",
      "Epoch 59/70\n",
      "7033/7033 [==============================] - 77s 11ms/step - loss: 0.4001 - accuracy: 0.1368 - val_loss: 0.4209 - val_accuracy: 0.1307 - lr: 4.2235e-04\n",
      "Epoch 60/70\n",
      "7030/7033 [============================>.] - ETA: 0s - loss: 0.3999 - accuracy: 0.1368\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 0.0003167635150020942.\n",
      "7033/7033 [==============================] - 76s 11ms/step - loss: 0.3999 - accuracy: 0.1368 - val_loss: 0.4209 - val_accuracy: 0.1347 - lr: 4.2235e-04\n",
      "Epoch 61/70\n",
      "7033/7033 [==============================] - 75s 11ms/step - loss: 0.4000 - accuracy: 0.1369 - val_loss: 0.4210 - val_accuracy: 0.1327 - lr: 3.1676e-04\n",
      "Epoch 62/70\n",
      "7033/7033 [==============================] - 83s 12ms/step - loss: 0.3998 - accuracy: 0.1373 - val_loss: 0.4209 - val_accuracy: 0.1310 - lr: 3.1676e-04\n",
      "Epoch 63/70\n",
      "7033/7033 [==============================] - ETA: 0s - loss: 0.3999 - accuracy: 0.1367\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.00023757264716550708.\n",
      "7033/7033 [==============================] - 87s 12ms/step - loss: 0.3999 - accuracy: 0.1367 - val_loss: 0.4209 - val_accuracy: 0.1312 - lr: 3.1676e-04\n",
      "Epoch 64/70\n",
      "7033/7033 [==============================] - 91s 13ms/step - loss: 0.3999 - accuracy: 0.1368 - val_loss: 0.4210 - val_accuracy: 0.1325 - lr: 2.3757e-04\n",
      "Epoch 65/70\n",
      "7033/7033 [==============================] - 79s 11ms/step - loss: 0.3999 - accuracy: 0.1368 - val_loss: 0.4210 - val_accuracy: 0.1326 - lr: 2.3757e-04\n",
      "Epoch 66/70\n",
      "7029/7033 [============================>.] - ETA: 0s - loss: 0.3997 - accuracy: 0.1370\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 0.0001781794853741303.\n",
      "7033/7033 [==============================] - 80s 11ms/step - loss: 0.3997 - accuracy: 0.1370 - val_loss: 0.4210 - val_accuracy: 0.1327 - lr: 2.3757e-04\n",
      "Epoch 67/70\n",
      "7033/7033 [==============================] - 80s 11ms/step - loss: 0.3995 - accuracy: 0.1372 - val_loss: 0.4209 - val_accuracy: 0.1325 - lr: 1.7818e-04\n",
      "Epoch 68/70\n",
      "7033/7033 [==============================] - 80s 11ms/step - loss: 0.3997 - accuracy: 0.1374 - val_loss: 0.4209 - val_accuracy: 0.1311 - lr: 1.7818e-04\n",
      "Epoch 69/70\n",
      "7030/7033 [============================>.] - ETA: 0s - loss: 0.3997 - accuracy: 0.1367\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 0.00013363461403059773.\n",
      "7033/7033 [==============================] - 82s 12ms/step - loss: 0.3997 - accuracy: 0.1367 - val_loss: 0.4211 - val_accuracy: 0.1325 - lr: 1.7818e-04\n",
      "Epoch 70/70\n",
      "7033/7033 [==============================] - 77s 11ms/step - loss: 0.3996 - accuracy: 0.1373 - val_loss: 0.4210 - val_accuracy: 0.1328 - lr: 1.3363e-04\n"
     ]
    }
   ],
   "source": [
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.75, patience=3, min_lr=0.000001, verbose=1)\n",
    "\n",
    "history = model.fit(x = X_train_array, y = y_train, batch_size=128, epochs=30, verbose=1, validation_data=(X_test_array, y_test)\n",
    ",shuffle=True,callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "568a6adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"loss\"][5:])\n",
    "plt.plot(history.history[\"val_loss\"][5:])\n",
    "plt.title(\"model loss\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"train\", \"test\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23c00bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98fcd43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([4343, 5184, 1604, ..., 1448,  689, 5625], dtype=int64),\n",
       " array([1154, 1007, 3342, ...,   12, 3293, 2743], dtype=int64)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "How DNN model works is, it takes two inputs, one of the input has user id's and the other has corresponding movie id's. \n",
    "Here DNN model tries to predict the ratings of the user - movie combination. \n",
    "So, we can input a specific user id (broadcasting it with the size of other input) and unseen movie id of the user and expect \n",
    "the model to give the ratings of the movies which would have been the ratings given by the user. \n",
    "Here, the ratings are already normalized and as we need the movies which interest the user more, \n",
    "ratings are not brought back to 0-5 scale.\n",
    "'''\n",
    "\n",
    "X_train_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ee90ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[258, 294, 707, 765, 921, 1007, 1290, 1628, 1637, 1724, 1860, 1869, 1973, 2164, 2503, 2548, 2677, 2979, 3257, 3630]\n"
     ]
    }
   ],
   "source": [
    "user_id = [2696] #movies seen by user_id\n",
    "encoded_user_id = user_enc.transform(user_id)\n",
    "\n",
    "seen_movies = list(refined_dataset[refined_dataset['user_id'] == user_id[0]]['movie'])\n",
    "print(seen_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4691a66b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3706, 0, 3705)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(refined_dataset['movie'].unique()), min(refined_dataset['movie']), max(refined_dataset['movie'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a665bac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1627, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1638, 1639, 1640, 1641, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1655, 1656, 1657, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1694, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1714, 1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1725, 1726, 1727, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1737, 1738, 1739, 1740, 1741, 1742, 1743, 1744, 1745, 1746, 1747, 1748, 1749, 1750, 1751, 1752, 1753, 1754, 1755, 1756, 1757, 1758, 1759, 1760, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1773, 1774, 1775, 1776, 1777, 1778, 1779, 1780, 1781, 1782, 1783, 1784, 1785, 1786, 1787, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1805, 1806, 1807, 1808, 1809, 1810, 1811, 1812, 1813, 1814, 1815, 1816, 1817, 1818, 1819, 1820, 1821, 1822, 1823, 1824, 1825, 1826, 1827, 1828, 1829, 1830, 1831, 1832, 1833, 1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1846, 1847, 1848, 1849, 1850, 1851, 1852, 1853, 1854, 1855, 1856, 1857, 1858, 1859, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1879, 1880, 1881, 1882, 1883, 1884, 1885, 1886, 1887, 1888, 1889, 1890, 1891, 1892, 1893, 1894, 1895, 1896, 1897, 1898, 1899, 1900, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1909, 1910, 1911, 1912, 1913, 1914, 1915, 1916, 1917, 1918, 1919, 1920, 1921, 1922, 1923, 1924, 1925, 1926, 1927, 1928, 1929, 1930, 1931, 1932, 1933, 1934, 1935, 1936, 1937, 1938, 1939, 1940, 1941, 1942, 1943, 1944, 1945, 1946, 1947, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1956, 1957, 1958, 1959, 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, 1970, 1971, 1972, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024, 2025, 2026, 2027, 2028, 2029, 2030, 2031, 2032, 2033, 2034, 2035, 2036, 2037, 2038, 2039, 2040, 2041, 2042, 2043, 2044, 2045, 2046, 2047, 2048, 2049, 2050, 2051, 2052, 2053, 2054, 2055, 2056, 2057, 2058, 2059, 2060, 2061, 2062, 2063, 2064, 2065, 2066, 2067, 2068, 2069, 2070, 2071, 2072, 2073, 2074, 2075, 2076, 2077, 2078, 2079, 2080, 2081, 2082, 2083, 2084, 2085, 2086, 2087, 2088, 2089, 2090, 2091, 2092, 2093, 2094, 2095, 2096, 2097, 2098, 2099, 2100, 2101, 2102, 2103, 2104, 2105, 2106, 2107, 2108, 2109, 2110, 2111, 2112, 2113, 2114, 2115, 2116, 2117, 2118, 2119, 2120, 2121, 2122, 2123, 2124, 2125, 2126, 2127, 2128, 2129, 2130, 2131, 2132, 2133, 2134, 2135, 2136, 2137, 2138, 2139, 2140, 2141, 2142, 2143, 2144, 2145, 2146, 2147, 2148, 2149, 2150, 2151, 2152, 2153, 2154, 2155, 2156, 2157, 2158, 2159, 2160, 2161, 2162, 2163, 2165, 2166, 2167, 2168, 2169, 2170, 2171, 2172, 2173, 2174, 2175, 2176, 2177, 2178, 2179, 2180, 2181, 2182, 2183, 2184, 2185, 2186, 2187, 2188, 2189, 2190, 2191, 2192, 2193, 2194, 2195, 2196, 2197, 2198, 2199, 2200, 2201, 2202, 2203, 2204, 2205, 2206, 2207, 2208, 2209, 2210, 2211, 2212, 2213, 2214, 2215, 2216, 2217, 2218, 2219, 2220, 2221, 2222, 2223, 2224, 2225, 2226, 2227, 2228, 2229, 2230, 2231, 2232, 2233, 2234, 2235, 2236, 2237, 2238, 2239, 2240, 2241, 2242, 2243, 2244, 2245, 2246, 2247, 2248, 2249, 2250, 2251, 2252, 2253, 2254, 2255, 2256, 2257, 2258, 2259, 2260, 2261, 2262, 2263, 2264, 2265, 2266, 2267, 2268, 2269, 2270, 2271, 2272, 2273, 2274, 2275, 2276, 2277, 2278, 2279, 2280, 2281, 2282, 2283, 2284, 2285, 2286, 2287, 2288, 2289, 2290, 2291, 2292, 2293, 2294, 2295, 2296, 2297, 2298, 2299, 2300, 2301, 2302, 2303, 2304, 2305, 2306, 2307, 2308, 2309, 2310, 2311, 2312, 2313, 2314, 2315, 2316, 2317, 2318, 2319, 2320, 2321, 2322, 2323, 2324, 2325, 2326, 2327, 2328, 2329, 2330, 2331, 2332, 2333, 2334, 2335, 2336, 2337, 2338, 2339, 2340, 2341, 2342, 2343, 2344, 2345, 2346, 2347, 2348, 2349, 2350, 2351, 2352, 2353, 2354, 2355, 2356, 2357, 2358, 2359, 2360, 2361, 2362, 2363, 2364, 2365, 2366, 2367, 2368, 2369, 2370, 2371, 2372, 2373, 2374, 2375, 2376, 2377, 2378, 2379, 2380, 2381, 2382, 2383, 2384, 2385, 2386, 2387, 2388, 2389, 2390, 2391, 2392, 2393, 2394, 2395, 2396, 2397, 2398, 2399, 2400, 2401, 2402, 2403, 2404, 2405, 2406, 2407, 2408, 2409, 2410, 2411, 2412, 2413, 2414, 2415, 2416, 2417, 2418, 2419, 2420, 2421, 2422, 2423, 2424, 2425, 2426, 2427, 2428, 2429, 2430, 2431, 2432, 2433, 2434, 2435, 2436, 2437, 2438, 2439, 2440, 2441, 2442, 2443, 2444, 2445, 2446, 2447, 2448, 2449, 2450, 2451, 2452, 2453, 2454, 2455, 2456, 2457, 2458, 2459, 2460, 2461, 2462, 2463, 2464, 2465, 2466, 2467, 2468, 2469, 2470, 2471, 2472, 2473, 2474, 2475, 2476, 2477, 2478, 2479, 2480, 2481, 2482, 2483, 2484, 2485, 2486, 2487, 2488, 2489, 2490, 2491, 2492, 2493, 2494, 2495, 2496, 2497, 2498, 2499, 2500, 2501, 2502, 2504, 2505, 2506, 2507, 2508, 2509, 2510, 2511, 2512, 2513, 2514, 2515, 2516, 2517, 2518, 2519, 2520, 2521, 2522, 2523, 2524, 2525, 2526, 2527, 2528, 2529, 2530, 2531, 2532, 2533, 2534, 2535, 2536, 2537, 2538, 2539, 2540, 2541, 2542, 2543, 2544, 2545, 2546, 2547, 2549, 2550, 2551, 2552, 2553, 2554, 2555, 2556, 2557, 2558, 2559, 2560, 2561, 2562, 2563, 2564, 2565, 2566, 2567, 2568, 2569, 2570, 2571, 2572, 2573, 2574, 2575, 2576, 2577, 2578, 2579, 2580, 2581, 2582, 2583, 2584, 2585, 2586, 2587, 2588, 2589, 2590, 2591, 2592, 2593, 2594, 2595, 2596, 2597, 2598, 2599, 2600, 2601, 2602, 2603, 2604, 2605, 2606, 2607, 2608, 2609, 2610, 2611, 2612, 2613, 2614, 2615, 2616, 2617, 2618, 2619, 2620, 2621, 2622, 2623, 2624, 2625, 2626, 2627, 2628, 2629, 2630, 2631, 2632, 2633, 2634, 2635, 2636, 2637, 2638, 2639, 2640, 2641, 2642, 2643, 2644, 2645, 2646, 2647, 2648, 2649, 2650, 2651, 2652, 2653, 2654, 2655, 2656, 2657, 2658, 2659, 2660, 2661, 2662, 2663, 2664, 2665, 2666, 2667, 2668, 2669, 2670, 2671, 2672, 2673, 2674, 2675, 2676, 2678, 2679, 2680, 2681, 2682, 2683, 2684, 2685, 2686, 2687, 2688, 2689, 2690, 2691, 2692, 2693, 2694, 2695, 2696, 2697, 2698, 2699, 2700, 2701, 2702, 2703, 2704, 2705, 2706, 2707, 2708, 2709, 2710, 2711, 2712, 2713, 2714, 2715, 2716, 2717, 2718, 2719, 2720, 2721, 2722, 2723, 2724, 2725, 2726, 2727, 2728, 2729, 2730, 2731, 2732, 2733, 2734, 2735, 2736, 2737, 2738, 2739, 2740, 2741, 2742, 2743, 2744, 2745, 2746, 2747, 2748, 2749, 2750, 2751, 2752, 2753, 2754, 2755, 2756, 2757, 2758, 2759, 2760, 2761, 2762, 2763, 2764, 2765, 2766, 2767, 2768, 2769, 2770, 2771, 2772, 2773, 2774, 2775, 2776, 2777, 2778, 2779, 2780, 2781, 2782, 2783, 2784, 2785, 2786, 2787, 2788, 2789, 2790, 2791, 2792, 2793, 2794, 2795, 2796, 2797, 2798, 2799, 2800, 2801, 2802, 2803, 2804, 2805, 2806, 2807, 2808, 2809, 2810, 2811, 2812, 2813, 2814, 2815, 2816, 2817, 2818, 2819, 2820, 2821, 2822, 2823, 2824, 2825, 2826, 2827, 2828, 2829, 2830, 2831, 2832, 2833, 2834, 2835, 2836, 2837, 2838, 2839, 2840, 2841, 2842, 2843, 2844, 2845, 2846, 2847, 2848, 2849, 2850, 2851, 2852, 2853, 2854, 2855, 2856, 2857, 2858, 2859, 2860, 2861, 2862, 2863, 2864, 2865, 2866, 2867, 2868, 2869, 2870, 2871, 2872, 2873, 2874, 2875, 2876, 2877, 2878, 2879, 2880, 2881, 2882, 2883, 2884, 2885, 2886, 2887, 2888, 2889, 2890, 2891, 2892, 2893, 2894, 2895, 2896, 2897, 2898, 2899, 2900, 2901, 2902, 2903, 2904, 2905, 2906, 2907, 2908, 2909, 2910, 2911, 2912, 2913, 2914, 2915, 2916, 2917, 2918, 2919, 2920, 2921, 2922, 2923, 2924, 2925, 2926, 2927, 2928, 2929, 2930, 2931, 2932, 2933, 2934, 2935, 2936, 2937, 2938, 2939, 2940, 2941, 2942, 2943, 2944, 2945, 2946, 2947, 2948, 2949, 2950, 2951, 2952, 2953, 2954, 2955, 2956, 2957, 2958, 2959, 2960, 2961, 2962, 2963, 2964, 2965, 2966, 2967, 2968, 2969, 2970, 2971, 2972, 2973, 2974, 2975, 2976, 2977, 2978, 2980, 2981, 2982, 2983, 2984, 2985, 2986, 2987, 2988, 2989, 2990, 2991, 2992, 2993, 2994, 2995, 2996, 2997, 2998, 2999, 3000, 3001, 3002, 3003, 3004, 3005, 3006, 3007, 3008, 3009, 3010, 3011, 3012, 3013, 3014, 3015, 3016, 3017, 3018, 3019, 3020, 3021, 3022, 3023, 3024, 3025, 3026, 3027, 3028, 3029, 3030, 3031, 3032, 3033, 3034, 3035, 3036, 3037, 3038, 3039, 3040, 3041, 3042, 3043, 3044, 3045, 3046, 3047, 3048, 3049, 3050, 3051, 3052, 3053, 3054, 3055, 3056, 3057, 3058, 3059, 3060, 3061, 3062, 3063, 3064, 3065, 3066, 3067, 3068, 3069, 3070, 3071, 3072, 3073, 3074, 3075, 3076, 3077, 3078, 3079, 3080, 3081, 3082, 3083, 3084, 3085, 3086, 3087, 3088, 3089, 3090, 3091, 3092, 3093, 3094, 3095, 3096, 3097, 3098, 3099, 3100, 3101, 3102, 3103, 3104, 3105, 3106, 3107, 3108, 3109, 3110, 3111, 3112, 3113, 3114, 3115, 3116, 3117, 3118, 3119, 3120, 3121, 3122, 3123, 3124, 3125, 3126, 3127, 3128, 3129, 3130, 3131, 3132, 3133, 3134, 3135, 3136, 3137, 3138, 3139, 3140, 3141, 3142, 3143, 3144, 3145, 3146, 3147, 3148, 3149, 3150, 3151, 3152, 3153, 3154, 3155, 3156, 3157, 3158, 3159, 3160, 3161, 3162, 3163, 3164, 3165, 3166, 3167, 3168, 3169, 3170, 3171, 3172, 3173, 3174, 3175, 3176, 3177, 3178, 3179, 3180, 3181, 3182, 3183, 3184, 3185, 3186, 3187, 3188, 3189, 3190, 3191, 3192, 3193, 3194, 3195, 3196, 3197, 3198, 3199, 3200, 3201, 3202, 3203, 3204, 3205, 3206, 3207, 3208, 3209, 3210, 3211, 3212, 3213, 3214, 3215, 3216, 3217, 3218, 3219, 3220, 3221, 3222, 3223, 3224, 3225, 3226, 3227, 3228, 3229, 3230, 3231, 3232, 3233, 3234, 3235, 3236, 3237, 3238, 3239, 3240, 3241, 3242, 3243, 3244, 3245, 3246, 3247, 3248, 3249, 3250, 3251, 3252, 3253, 3254, 3255, 3256, 3258, 3259, 3260, 3261, 3262, 3263, 3264, 3265, 3266, 3267, 3268, 3269, 3270, 3271, 3272, 3273, 3274, 3275, 3276, 3277, 3278, 3279, 3280, 3281, 3282, 3283, 3284, 3285, 3286, 3287, 3288, 3289, 3290, 3291, 3292, 3293, 3294, 3295, 3296, 3297, 3298, 3299, 3300, 3301, 3302, 3303, 3304, 3305, 3306, 3307, 3308, 3309, 3310, 3311, 3312, 3313, 3314, 3315, 3316, 3317, 3318, 3319, 3320, 3321, 3322, 3323, 3324, 3325, 3326, 3327, 3328, 3329, 3330, 3331, 3332, 3333, 3334, 3335, 3336, 3337, 3338, 3339, 3340, 3341, 3342, 3343, 3344, 3345, 3346, 3347, 3348, 3349, 3350, 3351, 3352, 3353, 3354, 3355, 3356, 3357, 3358, 3359, 3360, 3361, 3362, 3363, 3364, 3365, 3366, 3367, 3368, 3369, 3370, 3371, 3372, 3373, 3374, 3375, 3376, 3377, 3378, 3379, 3380, 3381, 3382, 3383, 3384, 3385, 3386, 3387, 3388, 3389, 3390, 3391, 3392, 3393, 3394, 3395, 3396, 3397, 3398, 3399, 3400, 3401, 3402, 3403, 3404, 3405, 3406, 3407, 3408, 3409, 3410, 3411, 3412, 3413, 3414, 3415, 3416, 3417, 3418, 3419, 3420, 3421, 3422, 3423, 3424, 3425, 3426, 3427, 3428, 3429, 3430, 3431, 3432, 3433, 3434, 3435, 3436, 3437, 3438, 3439, 3440, 3441, 3442, 3443, 3444, 3445, 3446, 3447, 3448, 3449, 3450, 3451, 3452, 3453, 3454, 3455, 3456, 3457, 3458, 3459, 3460, 3461, 3462, 3463, 3464, 3465, 3466, 3467, 3468, 3469, 3470, 3471, 3472, 3473, 3474, 3475, 3476, 3477, 3478, 3479, 3480, 3481, 3482, 3483, 3484, 3485, 3486, 3487, 3488, 3489, 3490, 3491, 3492, 3493, 3494, 3495, 3496, 3497, 3498, 3499, 3500, 3501, 3502, 3503, 3504, 3505, 3506, 3507, 3508, 3509, 3510, 3511, 3512, 3513, 3514, 3515, 3516, 3517, 3518, 3519, 3520, 3521, 3522, 3523, 3524, 3525, 3526, 3527, 3528, 3529, 3530, 3531, 3532, 3533, 3534, 3535, 3536, 3537, 3538, 3539, 3540, 3541, 3542, 3543, 3544, 3545, 3546, 3547, 3548, 3549, 3550, 3551, 3552, 3553, 3554, 3555, 3556, 3557, 3558, 3559, 3560, 3561, 3562, 3563, 3564, 3565, 3566, 3567, 3568, 3569, 3570, 3571, 3572, 3573, 3574, 3575, 3576, 3577, 3578, 3579, 3580, 3581, 3582, 3583, 3584, 3585, 3586, 3587, 3588, 3589, 3590, 3591, 3592, 3593, 3594, 3595, 3596, 3597, 3598, 3599, 3600, 3601, 3602, 3603, 3604, 3605, 3606, 3607, 3608, 3609, 3610, 3611, 3612, 3613, 3614, 3615, 3616, 3617, 3618, 3619, 3620, 3621, 3622, 3623, 3624, 3625, 3626, 3627, 3628, 3629, 3631, 3632, 3633, 3634, 3635, 3636, 3637, 3638, 3639, 3640, 3641, 3642, 3643, 3644, 3645, 3646, 3647, 3648, 3649, 3650, 3651, 3652, 3653, 3654, 3655, 3656, 3657, 3658, 3659, 3660, 3661, 3662, 3663, 3664, 3665, 3666, 3667, 3668, 3669, 3670, 3671, 3672, 3673, 3674, 3675, 3676, 3677, 3678, 3679, 3680, 3681, 3682, 3683, 3684, 3685, 3686, 3687, 3688, 3689, 3690, 3691, 3692, 3693, 3694, 3695, 3696, 3697, 3698, 3699, 3700, 3701, 3702, 3703, 3704, 3705]\n"
     ]
    }
   ],
   "source": [
    "unseen_movies = [i for i in range(min(refined_dataset['movie']), max(refined_dataset['movie'])+1) if i not in seen_movies]\n",
    "print(unseen_movies) #exclude 'seen movies'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "afcc2207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3706"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unseen_movies) + len(seen_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d352eb26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3686)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_input = [np.asarray(list(encoded_user_id)*len(unseen_movies)), np.asarray(unseen_movies)]\n",
    "len(model_input), len(model_input[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "31039816",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ratings = model.predict(model_input) #DNN model used to predict the ratings of 'unseen movies'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8966323a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predicted_ratings.shape)\n",
    "print(predicted_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "77a9d3dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99225414, 0.964602  , 0.99452716, ..., 0.9680973 , 0.9870323 ,\n",
       "       0.9583303 ], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_ratings = np.max(predicted_ratings, axis=1)\n",
    "#predicted_ratings.shape\n",
    "predicted_ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f14f1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3096 2452 1788 ... 3362 3653  970]\n"
     ]
    }
   ],
   "source": [
    "sorted_index = np.argsort(predicted_ratings)[::-1]\n",
    "print(sorted_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e1023a67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sour Grapes (1998)', \"One Flew Over the Cuckoo's Nest (1975)\",\n",
       "       \"Jupiter's Wife (1994)\", ...,\n",
       "       'Time Regained (Le Temps Retrouvé) (1999)',\n",
       "       'Withnail and I (1987)', 'Down Periscope (1996)'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommended_movies = item_enc.inverse_transform(sorted_index)\n",
    "recommended_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "64697434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sour Grapes (1998)',\n",
      " \"One Flew Over the Cuckoo's Nest (1975)\",\n",
      " \"Jupiter's Wife (1994)\",\n",
      " 'Ripe (1996)',\n",
      " 'Never Been Kissed (1999)',\n",
      " 'Misérables, Les (1998)',\n",
      " 'Steal This Movie! (2000)',\n",
      " 'Alligator (1980)',\n",
      " 'Strangeland (1998)',\n",
      " 'Soul Food (1997)',\n",
      " 'Problem Child 2 (1991)',\n",
      " 'Interiors (1978)',\n",
      " 'Star Trek: The Wrath of Khan (1982)',\n",
      " 'Stop! Or My Mom Will Shoot (1992)',\n",
      " 'History of the World: Part I (1981)',\n",
      " 'Home Alone (1990)',\n",
      " 'Blair Witch Project, The (1999)',\n",
      " 'Five Senses, The (1999)',\n",
      " 'Promise, The (La Promesse) (1996)',\n",
      " 'Home Alone 3 (1997)']\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint #recommended movies with Softmax DNN\n",
    "pprint(list(recommended_movies[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2699347a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommender_system(user_id, model, n_movies):\n",
    "\n",
    "  print(\"\")\n",
    "  print(\"Movie seen by the User:\")\n",
    "  pprint(list(refined_dataset[refined_dataset['user_id'] == user_id]['title']))\n",
    "  print(\"\")\n",
    "\n",
    "  encoded_user_id = user_enc.transform([user_id])\n",
    "\n",
    "  seen_movies = list(refined_dataset[refined_dataset['user_id'] == user_id]['movie'])\n",
    "  unseen_movies = [i for i in range(min(refined_dataset['movie']), max(refined_dataset['movie'])+1) if i not in seen_movies]\n",
    "  model_input = [np.asarray(list(encoded_user_id)*len(unseen_movies)), np.asarray(unseen_movies)]\n",
    "  predicted_ratings = model.predict(model_input)\n",
    "  predicted_ratings = np.max(predicted_ratings, axis=1)\n",
    "  sorted_index = np.argsort(predicted_ratings)[::-1]\n",
    "  recommended_movies = item_enc.inverse_transform(sorted_index)\n",
    "  print(\"---------------------------------------------------------------------------------\")\n",
    "  print(\"Top \"+str(n_movies)+\" Movie recommendations for User \"+str(user_id)+ \" are:\")\n",
    "  pprint(list(recommended_movies[:n_movies]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "97be696f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter user id\n",
      "888\n",
      "Enter number of movies to be recommended:\n",
      "10\n",
      "\n",
      "Movie seen by the User:\n",
      "['101 Dalmatians (1961)',\n",
      " 'Ace Ventura: Pet Detective (1994)',\n",
      " 'Ace Ventura: When Nature Calls (1995)',\n",
      " 'Air Force One (1997)',\n",
      " 'Aladdin and the King of Thieves (1996)',\n",
      " 'American Beauty (1999)',\n",
      " 'American Tail: Fievel Goes West, An (1991)',\n",
      " 'Anastasia (1997)',\n",
      " 'As Good As It Gets (1997)',\n",
      " 'Back to the Future (1985)',\n",
      " 'Beauty and the Beast (1991)',\n",
      " 'Being John Malkovich (1999)',\n",
      " 'Birdcage, The (1996)',\n",
      " 'Brady Bunch Movie, The (1995)',\n",
      " 'Braveheart (1995)',\n",
      " \"Bug's Life, A (1998)\",\n",
      " 'Clueless (1995)',\n",
      " 'Con Air (1997)',\n",
      " 'Dragonheart (1996)',\n",
      " 'Face/Off (1997)',\n",
      " 'Forrest Gump (1994)',\n",
      " 'Frequency (2000)',\n",
      " 'Full Monty, The (1997)',\n",
      " 'Glory (1989)',\n",
      " 'GoldenEye (1995)',\n",
      " 'Gremlins (1984)',\n",
      " 'Independence Day (ID4) (1996)',\n",
      " 'Indiana Jones and the Last Crusade (1989)',\n",
      " \"Jackie Chan's First Strike (1996)\",\n",
      " 'Jurassic Park (1993)',\n",
      " 'Kid, The (2000)',\n",
      " 'Lake Placid (1999)',\n",
      " 'Life Is Beautiful (La Vita è bella) (1997)',\n",
      " 'Lion King, The (1994)',\n",
      " 'Magnolia (1999)',\n",
      " 'Mars Attacks! (1996)',\n",
      " 'Matrix, The (1999)',\n",
      " 'Men in Black (1997)',\n",
      " 'Mission: Impossible 2 (2000)',\n",
      " 'Moonstruck (1987)',\n",
      " 'Mulan (1998)',\n",
      " 'Mumford (1999)',\n",
      " 'My Dog Skip (1999)',\n",
      " 'Nothing to Lose (1994)',\n",
      " 'Nutty Professor II: The Klumps (2000)',\n",
      " 'Philadelphia (1993)',\n",
      " 'Pocahontas (1995)',\n",
      " 'Pretty Woman (1990)',\n",
      " 'Prince of Egypt, The (1998)',\n",
      " 'Rock, The (1996)',\n",
      " 'Rush Hour (1998)',\n",
      " 'Saving Private Ryan (1998)',\n",
      " 'Scary Movie (2000)',\n",
      " 'Shakespeare in Love (1998)',\n",
      " 'South Park: Bigger, Longer and Uncut (1999)',\n",
      " 'Speed (1994)',\n",
      " 'Star Wars: Episode IV - A New Hope (1977)',\n",
      " 'Star Wars: Episode V - The Empire Strikes Back (1980)',\n",
      " 'Star Wars: Episode VI - Return of the Jedi (1983)',\n",
      " 'Stargate (1994)',\n",
      " 'Tarzan (1999)',\n",
      " 'Teaching Mrs. Tingle (1999)',\n",
      " 'Teenage Mutant Ninja Turtles (1990)',\n",
      " 'Terminator 2: Judgment Day (1991)',\n",
      " 'Terminator, The (1984)',\n",
      " 'Titan A.E. (2000)',\n",
      " 'Toy Story (1995)',\n",
      " 'Toy Story 2 (1999)',\n",
      " 'Twister (1996)',\n",
      " 'U-571 (2000)',\n",
      " 'Whole Nine Yards, The (2000)',\n",
      " 'X-Men (2000)']\n",
      "\n",
      "---------------------------------------------------------------------------------\n",
      "Top 10 Movie recommendations for User 888 are:\n",
      "['So Dear to My Heart (1949)',\n",
      " 'Odd Couple II, The (1998)',\n",
      " 'Jonah Who Will Be 25 in the Year 2000 (1976)',\n",
      " 'Replacement Killers, The (1998)',\n",
      " 'Mystery, Alaska (1999)',\n",
      " 'Mighty Peking Man (Hsing hsing wang) (1977)',\n",
      " 'Splash (1984)',\n",
      " \"All the King's Men (1949)\",\n",
      " 'Star Trek VI: The Undiscovered Country (1991)',\n",
      " 'Snowriders (1996)']\n"
     ]
    }
   ],
   "source": [
    "print(\"Enter user id\")\n",
    "user_id= int(input())\n",
    "\n",
    "print(\"Enter number of movies to be recommended:\")\n",
    "n_movies = int(input())\n",
    "recommender_system(user_id,model,n_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fab510",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
